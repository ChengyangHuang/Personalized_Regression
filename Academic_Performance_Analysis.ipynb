{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Academic Performance Analysis",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ChengyangHuang/Personalized_Regression/blob/main/Academic_Performance_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1PkK996LJPRh"
      },
      "source": [
        "import os\n",
        "\n",
        "if not os.path.exists(\"/content/student.zip\"):\n",
        "    !wget https://archive.ics.uci.edu/ml/machine-learning-databases/00320/student.zip\n",
        "if not (os.path.exists(\"/content/student-por.csv\") and os.path.exists(\"/content/student-por.csv\")):\n",
        "    !unzip /content/student.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wRWWorSvKdtB"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.impute import KNNImputer\n",
        "\n",
        "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
        "from sklearn.mixture import GaussianMixture, BayesianGaussianMixture\n",
        "from sklearn.neural_network import MLPClassifier, MLPRegressor\n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.manifold import TSNE\n",
        "\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, roc_auc_score\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "from scipy.spatial import KDTree\n",
        "from scipy.spatial import distance_matrix\n",
        "from scipy.special import softmax, expit\n",
        "\n",
        "import torch\n",
        "\n",
        "# np.random.seed(0)\n",
        "\n",
        "\n",
        "def make_mapping(column):\n",
        "    mapping = {}\n",
        "    for x in column:\n",
        "        if not (x in mapping.keys()):\n",
        "            mapping[x] = len(mapping)\n",
        "    return mapping\n",
        "\n",
        "\n",
        "def load_dataset(filepath = \"/content/student-por.csv\"):\n",
        "    dataset = pd.read_csv(filepath, sep=';')\n",
        "    print(dataset)\n",
        "    mapping_dict = {}\n",
        "    yn_mapping = {\"yes\": 1, \n",
        "                \"no\": 0}\n",
        "\n",
        "    X = []\n",
        "    for name, column in dataset.items():\n",
        "        column = column.values\n",
        "        if type(column[0]) == str:\n",
        "            if column[0] == \"yes\" or column[0] == \"no\":\n",
        "                mapping_dict[name] = yn_mapping\n",
        "                X.append([yn_mapping[x] for x in column])\n",
        "            elif name == \"Fjob\":\n",
        "                mapping = mapping_dict[\"Mjob\"]\n",
        "                mapping_dict[name] = mapping\n",
        "                X.append([mapping[x] for x in column])\n",
        "            else:\n",
        "                mapping = make_mapping(column)\n",
        "                mapping_dict[name] = mapping\n",
        "                X.append([mapping[x] for x in column])\n",
        "        else:\n",
        "            X.append(column)\n",
        "    \n",
        "    X = np.array(X).T\n",
        "    y = X[:, -3:]\n",
        "    X = X[:, :-3]\n",
        "    return X, y\n",
        "\n",
        "\n",
        "def print_metrics(dic):\n",
        "    message = f\"\\n\"\n",
        "    for k, v in dic.items():\n",
        "        message += f\"{k}:\\t{v}\\n\"\n",
        "    print(message)\n",
        "\n",
        "\n",
        "def evaluate_method(method, X_test, y_test, method_name, U_test=None):\n",
        "    if method_name == \"Personalized Regression\":\n",
        "        y_pred = method.predict(X_test, U_test)\n",
        "    else:\n",
        "        y_pred = method.predict(X_test)\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    R2 = r2_score(y_test, y_pred)\n",
        "    performance_dict = {\"method_name\": method_name,\n",
        "                        \"MSE\": mse,\n",
        "                        \"R2\": R2\n",
        "                        }\n",
        "    return performance_dict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JFhhox9rqDvy"
      },
      "source": [
        "class PRRegressor():\n",
        "    def __init__(self, args, theta_pop, trainset, validset=None):\n",
        "        # Training Parameters\n",
        "        self.cov_norm_ord = args.covariate_norm_ord\n",
        "        self.cov_xstart = args.covariate_x_start\n",
        "        self.cov_xend= args.covariate_x_end\n",
        "        self.sigma_theta = args.sigma_theta\n",
        "        self.lambd = args.theta_regularizer\n",
        "        self.gamma = args.distance_regularizer\n",
        "        self.nu = args.phi_regularizer\n",
        "        self.alpha = args.learning_rate\n",
        "        self.c = args.lr_decay\n",
        "        self.q = args.latent_dim\n",
        "        self.k = args.covariate_dim\n",
        "        self.log_steps = args.log_steps\n",
        "        self.n_neighbors = args.n_neighbors\n",
        "        self.show_logs = args.show_logs\n",
        "        self.use_distance_loss = args.use_distance_loss\n",
        "\n",
        "        self.theta_pop = torch.from_numpy(theta_pop).flatten()\n",
        "        self.n_features, self.n_outputs = theta_pop.shape\n",
        "\n",
        "        # Training Data\n",
        "        X_train, y_train, U_train = trainset\n",
        "        self.X_train = torch.from_numpy(X_train)\n",
        "        self.y_train = torch.from_numpy(y_train).to(dtype=torch.double)\n",
        "        self.__init_U_train(U_train)\n",
        "        self.n = self.X_train.shape[0]\n",
        "\n",
        "        # Validation Data\n",
        "        if type(validset) != \"NoneType\":\n",
        "            self.eval = True\n",
        "            self.X_eval, self.y_eval, self.U_eval = validset\n",
        "        else: \n",
        "            self.eval = False\n",
        "\n",
        "        # Variable Initialization\n",
        "        PI = np.random.multivariate_normal(theta_pop.flatten(), self.sigma_theta*np.eye(self.n_features*self.n_outputs), size=self.n)\n",
        "        self.PI = torch.from_numpy(PI)\n",
        "        self.Z, self.Q = self.__init_ZnQ(PI)\n",
        "        self.phi = torch.ones((self.k, ), dtype=torch.float64) / self.k\n",
        "\n",
        "        # Loss Functions\n",
        "        self.__sample_specific_loss = torch.nn.MSELoss(reduction=\"mean\")\n",
        "        self.__parameter_regularizer = torch.nn.L1Loss()\n",
        "        self.__phi_regularizer = torch.nn.MSELoss()\n",
        "        self.__distance_loss = torch.nn.MSELoss()\n",
        "\n",
        "\n",
        "    def train(self, n_epoch=5):\n",
        "        for epoch in range(n_epoch):\n",
        "            # Require Gradient for variables\n",
        "            Z = self.Z.clone().requires_grad_(True)\n",
        "            Q = self.Q.clone().requires_grad_(True)\n",
        "            phi = self.phi.clone().requires_grad_(True)\n",
        "            PI = self.__update_PI(Z, Q) \n",
        "\n",
        "            y_pred = self.__predict(self.X_train, PI)\n",
        "\n",
        "            # Calculate Loss\n",
        "            l_loss = self.__sample_specific_loss(y_pred, self.y_train)\n",
        "            D_loss = self.__distance_matching_regularizer(Z, phi) if self.use_distance_loss else 0\n",
        "            theta_loss = self.__parameter_regularizer(PI, torch.zeros_like(PI))\n",
        "            phi_sum = torch.sum(phi, dim=0, keepdim=True)\n",
        "            phi_loss = self.__phi_regularizer(phi_sum, torch.ones_like(phi_sum)) # Weight should sum to one\n",
        "            loss = l_loss + self.gamma * D_loss + self.lambd * theta_loss + self.nu * phi_loss\n",
        "            \n",
        "            # Update phi\n",
        "            loss.backward()\n",
        "            self.phi -= self.alpha * phi.grad\n",
        "\n",
        "            # Update Z\n",
        "            alpha_cust = self.alpha / torch.linalg.norm(self.PI-self.theta_pop, \n",
        "                                                        float('inf'), dim=1, keepdim=True)\n",
        "\n",
        "            # self.Z -= alpha_cust * Z.grad\n",
        "            self.Z -= torch.bmm(Z.grad.unsqueeze(2), alpha_cust.unsqueeze(2)).squeeze()\n",
        "\n",
        "            # Update Q\n",
        "            self.Q -= self.alpha * Q.grad\n",
        "\n",
        "            # Update alpha\n",
        "            self.alpha *= self.c\n",
        "\n",
        "            # Update theta, PI\n",
        "            self.PI = self.__update_PI(self.Z, self.Q)\n",
        "\n",
        "            if self.show_logs and epoch % self.log_steps == 0:\n",
        "                message = f\"Epoch {epoch+1} - Total loss: {loss}\\tDistance loss:{D_loss}\"\n",
        "                print(\"-\"*20)\n",
        "                print(message)\n",
        "                if self.eval:\n",
        "                    print_metrics(evaluate_method(self, self.X_eval, self.y_eval, \"Personalized Regression\", self.U_eval))\n",
        "                print(\"-\"*20)\n",
        "        \n",
        "\n",
        "    def predict(self, X_test, U_test):\n",
        "        X = torch.from_numpy(X_test)\n",
        "        dist_mat_test = self.__create_distance_matrix(self.U_train.numpy(), U_test)\n",
        "        _, idx_sets = torch.matmul(dist_mat_test, self.phi).topk(self.n_neighbors, dim=1)\n",
        "        PI = self.PI[idx_sets, :].mean(axis=1)\n",
        "        y_pred = self.__predict(X, PI).detach().numpy()\n",
        "        return y_pred\n",
        "\n",
        "\n",
        "    def __predict(self, X, PI):\n",
        "        pred = torch.bmm(X.unsqueeze(1), PI.view(-1, self.n_features, self.n_outputs)).squeeze()\n",
        "        return pred\n",
        "\n",
        "    def __create_distance_matrix(self, A, B):\n",
        "        dist_mat = []\n",
        "        for i in range(self.k):\n",
        "            dist_mat.append(distance_matrix(A[:, [i]], B[:, [i]], p=self.cov_norm_ord))\n",
        "        dist_mat = torch.from_numpy(np.array(dist_mat)).T\n",
        "        return dist_mat\n",
        "\n",
        "    def __init_U_train(self, U_train: np.array):\n",
        "        self.U_train = torch.from_numpy(U_train)\n",
        "        self.U_distance_mat = self.__create_distance_matrix(U_train, U_train)\n",
        "        # print(f\"Distance Matrix Shape: {self.U_distance_mat.shape}\")\n",
        "\n",
        "\n",
        "    def __init_ZnQ(self, PI):\n",
        "        pca = PCA(n_components=self.q, whiten=False)\n",
        "        Z = pca.fit_transform(PI)\n",
        "        Q = pca.components_\n",
        "        return torch.from_numpy(Z), torch.from_numpy(Q)\n",
        "    \n",
        "\n",
        "    def __update_PI(self, Z, Q):\n",
        "        return torch.mm(Z, Q) + self.theta_pop\n",
        "    \n",
        "\n",
        "    def __distance_matching_regularizer(self, Z, phi):       \n",
        "        _Z = Z.detach().numpy()\n",
        "        tree = KDTree(_Z)\n",
        "        _, idx_set = tree.query(_Z, k=6)\n",
        "        idx_set = idx_set[:, 1:]\n",
        "        Z_set = Z[idx_set, :]\n",
        "        delta_Z = Z.view(Z.shape[0], 1, -1).expand(-1, Z_set.shape[1], -1) - Z_set\n",
        "        delta_Z = torch.linalg.norm(delta_Z, ord=2, dim=2)\n",
        "\n",
        "        U_dist_idx = torch.from_numpy(idx_set).to(dtype=torch.int64).view(idx_set.shape[0], -1, 1).expand(-1, -1, self.k)\n",
        "        U_dist_set = torch.gather(self.U_distance_mat, 1, U_dist_idx)\n",
        "        rho_U = torch.matmul(U_dist_set, phi)\n",
        "        d_loss = self.__distance_loss(delta_Z, rho_U)\n",
        "        return d_loss\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "uSwrQf_7prQN",
        "outputId": "5ef5fa9e-f747-4813-a88a-bcad1b7d5658"
      },
      "source": [
        "class PR_Arguments():\n",
        "    # Data Arguments\n",
        "    sigma_theta = 0.01 #0.001\n",
        "    theta_regularizer = 0.01\n",
        "    distance_regularizer = 0.01\n",
        "    phi_regularizer = 0\n",
        "\n",
        "    # \n",
        "    n_neighbors = 3\n",
        "    latent_dim = 2\n",
        "    covariate_dim = 2\n",
        "    covariate_norm_ord = 2\n",
        "    covariate_x_start = 2\n",
        "    covariate_x_end = -1\n",
        "\n",
        "    # Traing Arguments\n",
        "    learning_rate = 0.001 #4e-3\n",
        "    lr_decay = 1 #1-1e-4\n",
        "    n_epoch = 5000 #2000\n",
        "    log_steps = 100\n",
        "    show_logs = True\n",
        "    use_distance_loss = False\n",
        "\n",
        "\n",
        "def main():\n",
        "    X, y = load_dataset()\n",
        "    y = y[:, [-1]]\n",
        "    print(y.shape)\n",
        "    U = TSNE().fit_transform(X[:, 2:])\n",
        "    plt.scatter(U[:, 0], U[:, 1])\n",
        "    plt.show()\n",
        "    X_train, X_test, y_train, y_test, U_train, U_test = train_test_split(X, y, U, test_size=0.33, random_state=42)\n",
        "\n",
        "    ## Preprocessing\n",
        "    # scaler =  StandardScaler()\n",
        "    # X_train = scaler.fit_transform(X_train)\n",
        "    # X_test = scaler.transform(X_test)\n",
        "\n",
        "    ### Methods\n",
        "    dict_list = []\n",
        "\n",
        "    ## Linear Regression\n",
        "    lr = LinearRegression().fit(X_train, y_train)\n",
        "    dict_lr = evaluate_method(lr, X_test, y_test, \"Linear Regression\")\n",
        "    dict_list.append(dict_lr)\n",
        "\n",
        "    ## Gaussian Mixture\n",
        "    # gmm = GaussianMixture(n_components=3).fit(X_train, y_train)\n",
        "    # dict_gmm = evaluate_method(gmm, X_test, y_test, \"Gaussian Mixture\")\n",
        "    # dict_list.append(dict_gmm)\n",
        "\n",
        "    # ## DNN\n",
        "    # dnn = MLPRegressor(hidden_layer_sizes=(100,)).fit(X_train, y_train.squeeze())\n",
        "    # dict_dnn = evaluate_method(dnn, X_test, y_test, \"Deep Neural Networks\")\n",
        "    # dict_list.append(dict_dnn)\n",
        "\n",
        "\n",
        "    # ## Personalized Regression\n",
        "    pr_args = PR_Arguments()\n",
        "    theta_lr = np.concatenate((np.array(lr.coef_), np.array(lr.intercept_).reshape((-1, 1))), axis=1).T\n",
        "    X_train = np.concatenate((X_train, np.ones((X_train.shape[0], 1))), axis=1)\n",
        "    X_test = np.concatenate((X_test, np.ones((X_test.shape[0], 1))), axis=1)\n",
        "    trainset = (X_train, y_train, U_train)\n",
        "    evalset = (X_test, y_test, U_test)\n",
        "    pr = PRRegressor(pr_args, theta_lr, trainset, evalset)\n",
        "    pr.train(pr_args.n_epoch)\n",
        "    dict_pr = evaluate_method(pr, X_test, y_test, \"Personalized Regression\", U_test)\n",
        "    dict_list.append(dict_pr) \n",
        "\n",
        "    for x in dict_list:\n",
        "        print_metrics(x)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "    school sex  age address famsize Pstatus  ...  Walc  health absences  G1  G2  G3\n",
            "0       GP   F   18       U     GT3       A  ...     1       3        4   0  11  11\n",
            "1       GP   F   17       U     GT3       T  ...     1       3        2   9  11  11\n",
            "2       GP   F   15       U     LE3       T  ...     3       3        6  12  13  12\n",
            "3       GP   F   15       U     GT3       T  ...     1       5        0  14  14  14\n",
            "4       GP   F   16       U     GT3       T  ...     2       5        0  11  13  13\n",
            "..     ...  ..  ...     ...     ...     ...  ...   ...     ...      ...  ..  ..  ..\n",
            "644     MS   F   19       R     GT3       T  ...     2       5        4  10  11  10\n",
            "645     MS   F   18       U     LE3       T  ...     1       1        4  15  15  16\n",
            "646     MS   F   18       U     GT3       T  ...     1       5        6  11  12   9\n",
            "647     MS   M   17       U     LE3       T  ...     4       2        6  10  10  10\n",
            "648     MS   M   18       R     LE3       T  ...     4       5        4  10  11  11\n",
            "\n",
            "[649 rows x 33 columns]\n",
            "(649, 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:446: UserWarning: Using a target size (torch.Size([434, 1])) that is different to the input size (torch.Size([434])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:446: UserWarning: Using a target size (torch.Size([434, 1])) that is different to the input size (torch.Size([434])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "--------------------\n",
            "Epoch 1 - Total loss: 14.64652627952575\tDistance loss:0\n",
            "\n",
            "method_name:\tPersonalized Regression\n",
            "MSE:\t7.822353998083331\n",
            "R2:\t0.25768043595972556\n",
            "\n",
            "--------------------\n",
            "--------------------\n",
            "Epoch 101 - Total loss: 12.94558140035771\tDistance loss:0\n",
            "\n",
            "method_name:\tPersonalized Regression\n",
            "MSE:\t7.927129024317691\n",
            "R2:\t0.24773757837291022\n",
            "\n",
            "--------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:446: UserWarning: Using a target size (torch.Size([434, 1])) that is different to the input size (torch.Size([434])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "--------------------\n",
            "Epoch 201 - Total loss: 11.551554595041178\tDistance loss:0\n",
            "\n",
            "method_name:\tPersonalized Regression\n",
            "MSE:\t8.485672361282438\n",
            "R2:\t0.1947333744600135\n",
            "\n",
            "--------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:446: UserWarning: Using a target size (torch.Size([434, 1])) that is different to the input size (torch.Size([434])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "--------------------\n",
            "Epoch 301 - Total loss: 10.817067471268023\tDistance loss:0\n",
            "\n",
            "method_name:\tPersonalized Regression\n",
            "MSE:\t9.673911183167988\n",
            "R2:\t0.08197282636235204\n",
            "\n",
            "--------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:446: UserWarning: Using a target size (torch.Size([434, 1])) that is different to the input size (torch.Size([434])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "--------------------\n",
            "Epoch 401 - Total loss: 10.516019954713338\tDistance loss:0\n",
            "\n",
            "method_name:\tPersonalized Regression\n",
            "MSE:\t10.293128010319654\n",
            "R2:\t0.023210877556371856\n",
            "\n",
            "--------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:446: UserWarning: Using a target size (torch.Size([434, 1])) that is different to the input size (torch.Size([434])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "--------------------\n",
            "Epoch 501 - Total loss: 10.406798128791811\tDistance loss:0\n",
            "\n",
            "method_name:\tPersonalized Regression\n",
            "MSE:\t10.574484483298477\n",
            "R2:\t-0.0034890665285831624\n",
            "\n",
            "--------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:446: UserWarning: Using a target size (torch.Size([434, 1])) that is different to the input size (torch.Size([434])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "--------------------\n",
            "Epoch 601 - Total loss: 10.363670227371886\tDistance loss:0\n",
            "\n",
            "method_name:\tPersonalized Regression\n",
            "MSE:\t10.707121220809471\n",
            "R2:\t-0.016075922759969608\n",
            "\n",
            "--------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:446: UserWarning: Using a target size (torch.Size([434, 1])) that is different to the input size (torch.Size([434])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "--------------------\n",
            "Epoch 701 - Total loss: 10.345953087848404\tDistance loss:0\n",
            "\n",
            "method_name:\tPersonalized Regression\n",
            "MSE:\t10.770491708728628\n",
            "R2:\t-0.022089605211146557\n",
            "\n",
            "--------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:446: UserWarning: Using a target size (torch.Size([434, 1])) that is different to the input size (torch.Size([434])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "--------------------\n",
            "Epoch 801 - Total loss: 10.339842780397598\tDistance loss:0\n",
            "\n",
            "method_name:\tPersonalized Regression\n",
            "MSE:\t10.798105533831722\n",
            "R2:\t-0.024710080149641378\n",
            "\n",
            "--------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:446: UserWarning: Using a target size (torch.Size([434, 1])) that is different to the input size (torch.Size([434])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "--------------------\n",
            "Epoch 901 - Total loss: 10.337320462592087\tDistance loss:0\n",
            "\n",
            "method_name:\tPersonalized Regression\n",
            "MSE:\t10.808371246150195\n",
            "R2:\t-0.02568426759943976\n",
            "\n",
            "--------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:446: UserWarning: Using a target size (torch.Size([434, 1])) that is different to the input size (torch.Size([434])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "--------------------\n",
            "Epoch 1001 - Total loss: 10.3361393479905\tDistance loss:0\n",
            "\n",
            "method_name:\tPersonalized Regression\n",
            "MSE:\t10.810914641952019\n",
            "R2:\t-0.025925628763004305\n",
            "\n",
            "--------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:446: UserWarning: Using a target size (torch.Size([434, 1])) that is different to the input size (torch.Size([434])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "--------------------\n",
            "Epoch 1101 - Total loss: 10.335558417499943\tDistance loss:0\n",
            "\n",
            "method_name:\tPersonalized Regression\n",
            "MSE:\t10.810016282809825\n",
            "R2:\t-0.025840376987522395\n",
            "\n",
            "--------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:446: UserWarning: Using a target size (torch.Size([434, 1])) that is different to the input size (torch.Size([434])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "--------------------\n",
            "Epoch 1201 - Total loss: 10.335261911546457\tDistance loss:0\n",
            "\n",
            "method_name:\tPersonalized Regression\n",
            "MSE:\t10.807751368050585\n",
            "R2:\t-0.02562544289772295\n",
            "\n",
            "--------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:446: UserWarning: Using a target size (torch.Size([434, 1])) that is different to the input size (torch.Size([434])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "--------------------\n",
            "Epoch 1301 - Total loss: 10.335106089002577\tDistance loss:0\n",
            "\n",
            "method_name:\tPersonalized Regression\n",
            "MSE:\t10.805129516005954\n",
            "R2:\t-0.02537663645566912\n",
            "\n",
            "--------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:446: UserWarning: Using a target size (torch.Size([434, 1])) that is different to the input size (torch.Size([434])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "--------------------\n",
            "Epoch 1401 - Total loss: 10.335022184202499\tDistance loss:0\n",
            "\n",
            "method_name:\tPersonalized Regression\n",
            "MSE:\t10.802617291423237\n",
            "R2:\t-0.02513823335380616\n",
            "\n",
            "--------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:446: UserWarning: Using a target size (torch.Size([434, 1])) that is different to the input size (torch.Size([434])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "--------------------\n",
            "Epoch 1501 - Total loss: 10.334976041460333\tDistance loss:0\n",
            "\n",
            "method_name:\tPersonalized Regression\n",
            "MSE:\t10.800403962180788\n",
            "R2:\t-0.024928194585586816\n",
            "\n",
            "--------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:446: UserWarning: Using a target size (torch.Size([434, 1])) that is different to the input size (torch.Size([434])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "--------------------\n",
            "Epoch 1601 - Total loss: 10.334950188629037\tDistance loss:0\n",
            "\n",
            "method_name:\tPersonalized Regression\n",
            "MSE:\t10.798541146256786\n",
            "R2:\t-0.024751418553086824\n",
            "\n",
            "--------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:446: UserWarning: Using a target size (torch.Size([434, 1])) that is different to the input size (torch.Size([434])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "--------------------\n",
            "Epoch 1701 - Total loss: 10.334935462751332\tDistance loss:0\n",
            "\n",
            "method_name:\tPersonalized Regression\n",
            "MSE:\t10.797015941263295\n",
            "R2:\t-0.02460668085569817\n",
            "\n",
            "--------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:446: UserWarning: Using a target size (torch.Size([434, 1])) that is different to the input size (torch.Size([434])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "--------------------\n",
            "Epoch 1801 - Total loss: 10.334926952217154\tDistance loss:0\n",
            "\n",
            "method_name:\tPersonalized Regression\n",
            "MSE:\t10.795788861882626\n",
            "R2:\t-0.024490234446967074\n",
            "\n",
            "--------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:446: UserWarning: Using a target size (torch.Size([434, 1])) that is different to the input size (torch.Size([434])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "--------------------\n",
            "Epoch 1901 - Total loss: 10.334921971089834\tDistance loss:0\n",
            "\n",
            "method_name:\tPersonalized Regression\n",
            "MSE:\t10.794812883422352\n",
            "R2:\t-0.02439761681481678\n",
            "\n",
            "--------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:446: UserWarning: Using a target size (torch.Size([434, 1])) that is different to the input size (torch.Size([434])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "--------------------\n",
            "Epoch 2001 - Total loss: 10.334919023520312\tDistance loss:0\n",
            "\n",
            "method_name:\tPersonalized Regression\n",
            "MSE:\t10.79404244219376\n",
            "R2:\t-0.024324504092346322\n",
            "\n",
            "--------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:446: UserWarning: Using a target size (torch.Size([434, 1])) that is different to the input size (torch.Size([434])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "--------------------\n",
            "Epoch 2101 - Total loss: 10.334917262671743\tDistance loss:0\n",
            "\n",
            "method_name:\tPersonalized Regression\n",
            "MSE:\t10.793437196048204\n",
            "R2:\t-0.024267067922234986\n",
            "\n",
            "--------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:446: UserWarning: Using a target size (torch.Size([434, 1])) that is different to the input size (torch.Size([434])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "--------------------\n",
            "Epoch 2201 - Total loss: 10.334916202078533\tDistance loss:0\n",
            "\n",
            "method_name:\tPersonalized Regression\n",
            "MSE:\t10.792963131358155\n",
            "R2:\t-0.02422208050615393\n",
            "\n",
            "--------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:446: UserWarning: Using a target size (torch.Size([434, 1])) that is different to the input size (torch.Size([434])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "--------------------\n",
            "Epoch 2301 - Total loss: 10.33491555867502\tDistance loss:0\n",
            "\n",
            "method_name:\tPersonalized Regression\n",
            "MSE:\t10.79259240452617\n",
            "R2:\t-0.024186899564411224\n",
            "\n",
            "--------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:446: UserWarning: Using a target size (torch.Size([434, 1])) that is different to the input size (torch.Size([434])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "--------------------\n",
            "Epoch 2401 - Total loss: 10.334915165891564\tDistance loss:0\n",
            "\n",
            "method_name:\tPersonalized Regression\n",
            "MSE:\t10.792302649962703\n",
            "R2:\t-0.024159402664976293\n",
            "\n",
            "--------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:446: UserWarning: Using a target size (torch.Size([434, 1])) that is different to the input size (torch.Size([434])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "--------------------\n",
            "Epoch 2501 - Total loss: 10.334914924751352\tDistance loss:0\n",
            "\n",
            "method_name:\tPersonalized Regression\n",
            "MSE:\t10.79207612080117\n",
            "R2:\t-0.02413790567973706\n",
            "\n",
            "--------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:446: UserWarning: Using a target size (torch.Size([434, 1])) that is different to the input size (torch.Size([434])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "--------------------\n",
            "Epoch 2601 - Total loss: 10.334914775937586\tDistance loss:0\n",
            "\n",
            "method_name:\tPersonalized Regression\n",
            "MSE:\t10.791898878776534\n",
            "R2:\t-0.024121085906240625\n",
            "\n",
            "--------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:446: UserWarning: Using a target size (torch.Size([434, 1])) that is different to the input size (torch.Size([434])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "--------------------\n",
            "Epoch 2701 - Total loss: 10.334914683643701\tDistance loss:0\n",
            "\n",
            "method_name:\tPersonalized Regression\n",
            "MSE:\t10.791760008352504\n",
            "R2:\t-0.02410790749055547\n",
            "\n",
            "--------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:446: UserWarning: Using a target size (torch.Size([434, 1])) that is different to the input size (torch.Size([434])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "--------------------\n",
            "Epoch 2801 - Total loss: 10.334914626115504\tDistance loss:0\n",
            "\n",
            "method_name:\tPersonalized Regression\n",
            "MSE:\t10.79165100251315\n",
            "R2:\t-0.024097563140610845\n",
            "\n",
            "--------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:446: UserWarning: Using a target size (torch.Size([434, 1])) that is different to the input size (torch.Size([434])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "--------------------\n",
            "Epoch 2901 - Total loss: 10.334914590062262\tDistance loss:0\n",
            "\n",
            "method_name:\tPersonalized Regression\n",
            "MSE:\t10.791565246461143\n",
            "R2:\t-0.024089425130600528\n",
            "\n",
            "--------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:446: UserWarning: Using a target size (torch.Size([434, 1])) that is different to the input size (torch.Size([434])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "--------------------\n",
            "Epoch 3001 - Total loss: 10.334914567324038\tDistance loss:0\n",
            "\n",
            "method_name:\tPersonalized Regression\n",
            "MSE:\t10.791497602241602\n",
            "R2:\t-0.02408300588294532\n",
            "\n",
            "--------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:446: UserWarning: Using a target size (torch.Size([434, 1])) that is different to the input size (torch.Size([434])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "--------------------\n",
            "Epoch 3101 - Total loss: 10.334914552869193\tDistance loss:0\n",
            "\n",
            "method_name:\tPersonalized Regression\n",
            "MSE:\t10.791444080272854\n",
            "R2:\t-0.024077926797478444\n",
            "\n",
            "--------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:446: UserWarning: Using a target size (torch.Size([434, 1])) that is different to the input size (torch.Size([434])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "--------------------\n",
            "Epoch 3201 - Total loss: 10.33491454358308\tDistance loss:0\n",
            "\n",
            "method_name:\tPersonalized Regression\n",
            "MSE:\t10.791401581922354\n",
            "R2:\t-0.024073893822619263\n",
            "\n",
            "--------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:446: UserWarning: Using a target size (torch.Size([434, 1])) that is different to the input size (torch.Size([434])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "--------------------\n",
            "Epoch 3301 - Total loss: 10.334914537531024\tDistance loss:0\n",
            "\n",
            "method_name:\tPersonalized Regression\n",
            "MSE:\t10.791367698959228\n",
            "R2:\t-0.02407067842397792\n",
            "\n",
            "--------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:446: UserWarning: Using a target size (torch.Size([434, 1])) that is different to the input size (torch.Size([434])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "--------------------\n",
            "Epoch 3401 - Total loss: 10.334914533507538\tDistance loss:0\n",
            "\n",
            "method_name:\tPersonalized Regression\n",
            "MSE:\t10.79134055793504\n",
            "R2:\t-0.024068102816526826\n",
            "\n",
            "--------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:446: UserWarning: Using a target size (torch.Size([434, 1])) that is different to the input size (torch.Size([434])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "--------------------\n",
            "Epoch 3501 - Total loss: 10.33491453075938\tDistance loss:0\n",
            "\n",
            "method_name:\tPersonalized Regression\n",
            "MSE:\t10.79131869972673\n",
            "R2:\t-0.024066028533559658\n",
            "\n",
            "--------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:446: UserWarning: Using a target size (torch.Size([434, 1])) that is different to the input size (torch.Size([434])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "--------------------\n",
            "Epoch 3601 - Total loss: 10.334914528814677\tDistance loss:0\n",
            "\n",
            "method_name:\tPersonalized Regression\n",
            "MSE:\t10.7913009864229\n",
            "R2:\t-0.024064347590459834\n",
            "\n",
            "--------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:446: UserWarning: Using a target size (torch.Size([434, 1])) that is different to the input size (torch.Size([434])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "--------------------\n",
            "Epoch 3701 - Total loss: 10.334914527377126\tDistance loss:0\n",
            "\n",
            "method_name:\tPersonalized Regression\n",
            "MSE:\t10.791286529382418\n",
            "R2:\t-0.024062975657664243\n",
            "\n",
            "--------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:446: UserWarning: Using a target size (torch.Size([434, 1])) that is different to the input size (torch.Size([434])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "--------------------\n",
            "Epoch 3801 - Total loss: 10.334914526260267\tDistance loss:0\n",
            "\n",
            "method_name:\tPersonalized Regression\n",
            "MSE:\t10.791274633642455\n",
            "R2:\t-0.024061846785140117\n",
            "\n",
            "--------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:446: UserWarning: Using a target size (torch.Size([434, 1])) that is different to the input size (torch.Size([434])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "--------------------\n",
            "Epoch 3901 - Total loss: 10.334914525346532\tDistance loss:0\n",
            "\n",
            "method_name:\tPersonalized Regression\n",
            "MSE:\t10.791264754932786\n",
            "R2:\t-0.024060909323161628\n",
            "\n",
            "--------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:446: UserWarning: Using a target size (torch.Size([434, 1])) that is different to the input size (torch.Size([434])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "--------------------\n",
            "Epoch 4001 - Total loss: 10.334914524561654\tDistance loss:0\n",
            "\n",
            "method_name:\tPersonalized Regression\n",
            "MSE:\t10.791256466404144\n",
            "R2:\t-0.024060122764924863\n",
            "\n",
            "--------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:446: UserWarning: Using a target size (torch.Size([434, 1])) that is different to the input size (torch.Size([434])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "--------------------\n",
            "Epoch 4101 - Total loss: 10.334914523858638\tDistance loss:0\n",
            "\n",
            "method_name:\tPersonalized Regression\n",
            "MSE:\t10.791249432842612\n",
            "R2:\t-0.024059455299564547\n",
            "\n",
            "--------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:446: UserWarning: Using a target size (torch.Size([434, 1])) that is different to the input size (torch.Size([434])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "--------------------\n",
            "Epoch 4201 - Total loss: 10.334914523207695\tDistance loss:0\n",
            "\n",
            "method_name:\tPersonalized Regression\n",
            "MSE:\t10.791243390656653\n",
            "R2:\t-0.024058881912979224\n",
            "\n",
            "--------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:446: UserWarning: Using a target size (torch.Size([434, 1])) that is different to the input size (torch.Size([434])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "--------------------\n",
            "Epoch 4301 - Total loss: 10.334914522589925\tDistance loss:0\n",
            "\n",
            "method_name:\tPersonalized Regression\n",
            "MSE:\t10.791238132320062\n",
            "R2:\t-0.024058382911511744\n",
            "\n",
            "--------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:446: UserWarning: Using a target size (torch.Size([434, 1])) that is different to the input size (torch.Size([434])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "--------------------\n",
            "Epoch 4401 - Total loss: 10.334914521993309\tDistance loss:0\n",
            "\n",
            "method_name:\tPersonalized Regression\n",
            "MSE:\t10.791233494258895\n",
            "R2:\t-0.02405794277245077\n",
            "\n",
            "--------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:446: UserWarning: Using a target size (torch.Size([434, 1])) that is different to the input size (torch.Size([434])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "--------------------\n",
            "Epoch 4501 - Total loss: 10.334914521410198\tDistance loss:0\n",
            "\n",
            "method_name:\tPersonalized Regression\n",
            "MSE:\t10.791229347404327\n",
            "R2:\t-0.024057549247525234\n",
            "\n",
            "--------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:446: UserWarning: Using a target size (torch.Size([434, 1])) that is different to the input size (torch.Size([434])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "--------------------\n",
            "Epoch 4601 - Total loss: 10.334914520835719\tDistance loss:0\n",
            "\n",
            "method_name:\tPersonalized Regression\n",
            "MSE:\t10.791225589812687\n",
            "R2:\t-0.024057192662565008\n",
            "\n",
            "--------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:446: UserWarning: Using a target size (torch.Size([434, 1])) that is different to the input size (torch.Size([434])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "--------------------\n",
            "Epoch 4701 - Total loss: 10.334914520266768\tDistance loss:0\n",
            "\n",
            "method_name:\tPersonalized Regression\n",
            "MSE:\t10.791222140890891\n",
            "R2:\t-0.024056865369511682\n",
            "\n",
            "--------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:446: UserWarning: Using a target size (torch.Size([434, 1])) that is different to the input size (torch.Size([434])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "--------------------\n",
            "Epoch 4801 - Total loss: 10.334914519701352\tDistance loss:0\n",
            "\n",
            "method_name:\tPersonalized Regression\n",
            "MSE:\t10.791218936871193\n",
            "R2:\t-0.024056561316984082\n",
            "\n",
            "--------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:446: UserWarning: Using a target size (torch.Size([434, 1])) that is different to the input size (torch.Size([434])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "--------------------\n",
            "Epoch 4901 - Total loss: 10.334914519138204\tDistance loss:0\n",
            "\n",
            "method_name:\tPersonalized Regression\n",
            "MSE:\t10.791215927259667\n",
            "R2:\t-0.02405627571324942\n",
            "\n",
            "--------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:446: UserWarning: Using a target size (torch.Size([434, 1])) that is different to the input size (torch.Size([434])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "method_name:\tLinear Regression\n",
            "MSE:\t7.843097335056123\n",
            "R2:\t0.25571195117085554\n",
            "\n",
            "\n",
            "method_name:\tPersonalized Regression\n",
            "MSE:\t10.791213099942992\n",
            "R2:\t-0.024056007408787217\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}